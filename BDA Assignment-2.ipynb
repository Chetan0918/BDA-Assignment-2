{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQDrDveK084ovEadBDivRN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Q1 Build a Classification Model with Spark with a dataset of your choice\n","#Classification using PySpark (Iris Dataset)"],"metadata":{"id":"1BHVTr9-colS","executionInfo":{"status":"ok","timestamp":1745593210387,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Install PySpark\n","!pip install pyspark\n","\n","# Import Libraries\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","import pandas as pd\n","from sklearn.datasets import load_iris\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJbePphlcojF","executionInfo":{"status":"ok","timestamp":1745593214866,"user_tz":-330,"elapsed":3331,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"79460230-6b88-4ba3-b149-1e81e3befd55"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"]}]},{"cell_type":"code","source":["# Start Spark session\n","spark = SparkSession.builder.appName(\"Iris_Classification\").getOrCreate()\n","\n","# Load Iris dataset using sklearn\n","iris = load_iris()\n","iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","iris_df[\"target\"] = iris.target\n","\n","# Convert to Spark DataFrame\n","spark_iris_df = spark.createDataFrame(iris_df)\n","spark_iris_df.show(5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8xJggc5Hcogl","executionInfo":{"status":"ok","timestamp":1745593219706,"user_tz":-330,"elapsed":2094,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"1d28ec51-2e87-4248-8bae-1ba5c8c5dfad"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------+----------------+-----------------+----------------+------+\n","|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|\n","+-----------------+----------------+-----------------+----------------+------+\n","|              5.1|             3.5|              1.4|             0.2|     0|\n","|              4.9|             3.0|              1.4|             0.2|     0|\n","|              4.7|             3.2|              1.3|             0.2|     0|\n","|              4.6|             3.1|              1.5|             0.2|     0|\n","|              5.0|             3.6|              1.4|             0.2|     0|\n","+-----------------+----------------+-----------------+----------------+------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","source":["# Assemble features into a single vector column\n","vectorizer = VectorAssembler(inputCols=iris.feature_names, outputCol=\"features\")\n","iris_data = vectorizer.transform(spark_iris_df)\n","\n","# Split data into training and test sets\n","train_data, test_data = iris_data.randomSplit([0.75, 0.25], seed=10)\n","\n","# Train a Random Forest Classifier\n","rf = RandomForestClassifier(labelCol=\"target\", featuresCol=\"features\", numTrees=20)\n","rf_model = rf.fit(train_data)\n"],"metadata":{"id":"jToZ4qThcodZ","executionInfo":{"status":"ok","timestamp":1745593231749,"user_tz":-330,"elapsed":10057,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Predict on test set\n","rf_preds = rf_model.transform(test_data)\n","\n","# Evaluate accuracy\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(rf_preds)\n","print(f\"Random Forest Model Accuracy: {accuracy:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-cXXrfVdmYI","executionInfo":{"status":"ok","timestamp":1745593236229,"user_tz":-330,"elapsed":887,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"fe3e029c-d735-42c2-b174-93b7b0ad780d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest Model Accuracy: 0.976\n"]}]},{"cell_type":"code","source":["#Q2 Build a Clustering Model with Spark with a dataset of your choice.\n","#Question 2: Clustering using PySpark (Mall Customers Dataset)"],"metadata":{"id":"fmEnHi3rdmap","executionInfo":{"status":"ok","timestamp":1745593398505,"user_tz":-330,"elapsed":49,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Already installed pyspark earlier\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.clustering import KMeans\n","import pandas as pd\n","\n","# Start Spark session (if not already started)\n","spark = SparkSession.builder.appName(\"Customer_Clustering\").getOrCreate()\n"],"metadata":{"id":"dwmgaaCud5yT","executionInfo":{"status":"ok","timestamp":1745593399473,"user_tz":-330,"elapsed":14,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Sample Mall Customer Data\n","data = pd.DataFrame({\n","    \"CustID\": [1, 2, 3, 4, 5],\n","    \"Age\": [18, 22, 24, 35, 45],\n","    \"Income\": [15, 18, 20, 25, 30],\n","    \"Score\": [39, 81, 6, 77, 40]\n","})\n","\n","# Convert to Spark DataFrame\n","customer_df = spark.createDataFrame(data)\n","customer_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxzOFrL9d8K-","executionInfo":{"status":"ok","timestamp":1745593401893,"user_tz":-330,"elapsed":681,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"224a42a2-c832-4ff7-d5f8-d75309415313"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+---+------+-----+\n","|CustID|Age|Income|Score|\n","+------+---+------+-----+\n","|     1| 18|    15|   39|\n","|     2| 22|    18|   81|\n","|     3| 24|    20|    6|\n","|     4| 35|    25|   77|\n","|     5| 45|    30|   40|\n","+------+---+------+-----+\n","\n"]}]},{"cell_type":"code","source":["# Assemble features\n","assembler = VectorAssembler(inputCols=[\"Age\", \"Income\", \"Score\"], outputCol=\"features\")\n","features_df = assembler.transform(customer_df)\n","\n","# Apply KMeans Clustering\n","kmeans = KMeans(k=2, seed=15)\n","k_model = kmeans.fit(features_df)\n","\n","# Make predictions\n","clustered_df = k_model.transform(features_df)\n"],"metadata":{"id":"ycIBEJyRd592","executionInfo":{"status":"ok","timestamp":1745593410339,"user_tz":-330,"elapsed":5849,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Display cluster assignments\n","clustered_df.select(\"CustID\", \"prediction\").show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCjewx_2d6Bz","executionInfo":{"status":"ok","timestamp":1745593412327,"user_tz":-330,"elapsed":564,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"fed273a8-09b1-4d63-9487-96cefcfbed64"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+----------+\n","|CustID|prediction|\n","+------+----------+\n","|     1|         0|\n","|     2|         1|\n","|     3|         0|\n","|     4|         1|\n","|     5|         0|\n","+------+----------+\n","\n"]}]},{"cell_type":"code","source":["##Q3 Build a Recommendation Engine with Spark with a dataset of your choice\n","#Question 3: Recommendation Engine using PySpark ALS"],"metadata":{"id":"ZoVNior5d6Ff","executionInfo":{"status":"ok","timestamp":1745593414385,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Already installed pyspark earlier\n","from pyspark.sql import SparkSession\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import pandas as pd\n","\n","# Create or use existing Spark session\n","spark = SparkSession.builder.appName(\"ALS_Recommendation\").getOrCreate()\n"],"metadata":{"id":"GKktlLjbeCP2","executionInfo":{"status":"ok","timestamp":1745593415821,"user_tz":-330,"elapsed":17,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Sample user-item ratings data\n","ratings_data = pd.DataFrame({\n","    \"user\": [101, 101, 102, 103, 104],\n","    \"item\": [201, 202, 201, 203, 204],\n","    \"score\": [4.5, 5.0, 3.5, 4.0, 2.0]\n","})\n","\n","# Convert to Spark DataFrame\n","ratings_df = spark.createDataFrame(ratings_data)\n","ratings_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIVd317SeOYI","executionInfo":{"status":"ok","timestamp":1745593417591,"user_tz":-330,"elapsed":539,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"a184cbda-91c2-4f6b-dc16-ae139482a925"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----+-----+\n","|user|item|score|\n","+----+----+-----+\n","| 101| 201|  4.5|\n","| 101| 202|  5.0|\n","| 102| 201|  3.5|\n","| 103| 203|  4.0|\n","| 104| 204|  2.0|\n","+----+----+-----+\n","\n"]}]},{"cell_type":"code","source":["# Build ALS recommender\n","als = ALS(userCol=\"user\", itemCol=\"item\", ratingCol=\"score\", nonnegative=True, coldStartStrategy=\"drop\")\n","als_model = als.fit(ratings_df)\n"],"metadata":{"id":"eP2QzwEVeCTE","executionInfo":{"status":"ok","timestamp":1745593430356,"user_tz":-330,"elapsed":10683,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Predict on known data\n","predictions = als_model.transform(ratings_df)\n","\n","# Evaluate with RMSE\n","evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"score\", predictionCol=\"prediction\")\n","rmse = evaluator.evaluate(predictions)\n","print(f\"ALS Model RMSE: {rmse:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkAjsCpWeCVv","executionInfo":{"status":"ok","timestamp":1745593434002,"user_tz":-330,"elapsed":2436,"user":{"displayName":"Chetan Balugu","userId":"14269548958019795040"}},"outputId":"da2cc07e-f5b1-4e0b-c984-bb88482530c0"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["ALS Model RMSE: 0.065\n"]}]}]}